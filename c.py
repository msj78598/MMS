# -*- coding: utf-8 -*-
# mms_premise_tracker.py â€” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ø¯Ø§Ø¯Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ØªØµÙ„Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Premise ÙƒÙ…ÙØªØ§Ø­

import re
import numpy as np
import pandas as pd
import streamlit as st
from datetime import datetime
from io import BytesIO

st.set_page_config(page_title="MMS | Premise Tracker", layout="wide")

# ============ Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© ============
def norm_col(c: str) -> str:
    return re.sub(r"\s+", " ", str(c).strip()).lower()

def smart_parse_datetime(series: pd.Series) -> pd.Series:
    """Ù…Ø­Ù„Ù„ Ø°ÙƒÙŠ Ù„ØªÙˆØ§Ø±ÙŠØ® Excel ÙˆØ§Ù„Ù†ØµÙˆØµ"""
    if series is None:
        return pd.Series([], dtype="datetime64[ns]")
    s = series.copy()

    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ
    def clean(x):
        if pd.isna(x):
            return np.nan
        x = str(x).strip()
        if x == "" or x.lower() in {"none", "nan", "null", "-", "â€”", "0"}:
            return np.nan
        return x
    s = s.map(clean)

    parsed = pd.to_datetime(s, errors="coerce", dayfirst=True, infer_datetime_format=True)
    # ØªØ­ÙˆÙŠÙ„ Ø³ÙŠØ±ÙŠØ§Ù„ Excel
    need_excel = parsed.isna()
    if need_excel.any():
        as_num = pd.to_numeric(s.where(need_excel), errors="coerce")
        excel_mask = as_num.notna()
        if excel_mask.any():
            excel_dates = pd.to_datetime(as_num[excel_mask], unit="d", origin="1899-12-30", errors="coerce")
            parsed.loc[excel_mask] = excel_dates
    return parsed

def pick_col(df, candidates):
    nm = {norm_col(c): c for c in df.columns}
    for c in candidates:
        if norm_col(c) in nm:
            return nm[norm_col(c)]
    for c in df.columns:
        for cand in candidates:
            if norm_col(cand) in norm_col(c):
                return c
    return None

def to_excel_download(df: pd.DataFrame) -> bytes:
    """ØªØ­ÙˆÙŠÙ„ DataFrame Ø¥Ù„Ù‰ Ù…Ù„Ù Excel Ø¬Ø§Ù‡Ø² Ù„Ù„ØªÙ†Ø²ÙŠÙ„"""
    output = BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name="Results")
    return output.getvalue()

# ============ Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª ============
st.title("ğŸ“Š Ù†Ø¸Ø§Ù… ØªØªØ¨Ø¹ Ø§Ù„Ø¹Ø¯Ø§Ø¯Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ØªØµÙ„Ø© - Premise Tracker")

with st.sidebar:
    st.header("ğŸ“ Ù…Ù„ÙØ§Øª Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„")
    disconnected_file = st.file_uploader("Ù…Ù„Ù Ø§Ù„Ø¹Ø¯Ø§Ø¯Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ØªØµÙ„Ø©", type=["xlsx", "xls"])
    insp_file = st.file_uploader("Ù…Ù„Ù Ù…Ù‡Ø§Ù… Ø§Ù„ÙØ­Øµ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)", type=["xlsx", "xls"])
    maint_file = st.file_uploader("Ù…Ù„Ù Ù…Ù‡Ø§Ù… Ø§Ù„ØµÙŠØ§Ù†Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)", type=["xlsx", "xls"])
    st.markdown("---")
    start_btn = st.button("ğŸš€ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ­Ù„ÙŠÙ„")

if not start_btn or not disconnected_file:
    st.info("â¬†ï¸ Ø§Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø«Ù… Ø§Ø¶ØºØ· **Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ­Ù„ÙŠÙ„** Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©.")
    st.stop()

# ============ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ø¹Ø¯Ø§Ø¯Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ØªØµÙ„Ø© ============
st.subheader("ğŸ“˜ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ø¹Ø¯Ø§Ø¯Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ØªØµÙ„Ø©")
dis_df = pd.read_excel(disconnected_file)
col_premise = pick_col(dis_df, ["Utility Site Id", "Premise", "Ø±Ù‚Ù… Ø§Ù„Ù…ÙƒØ§Ù†"])
col_last = pick_col(dis_df, ["Last Daily", "Last Communication", "Ø¢Ø®Ø± Ù‚Ø±Ø§Ø¡Ø©", "Ø¢Ø®Ø± Ø§ØªØµØ§Ù„"])
if not col_premise:
    st.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ Ø±Ù‚Ù… Ø§Ù„Ù…ÙƒØ§Ù† (Utility Site Id) ÙÙŠ Ø§Ù„Ù…Ù„Ù.")
    st.stop()

dis_df["_KEY_PREMISE"] = dis_df[col_premise].astype(str).str.strip()
if col_last:
    dis_df[col_last] = smart_parse_datetime(dis_df[col_last])
    st.success(f"ØªÙ… ØªØ­ÙˆÙŠÙ„ Ø¹Ù…ÙˆØ¯ Ø¢Ø®Ø± Ø§ØªØµØ§Ù„ ({col_last}) Ø¥Ù„Ù‰ ØªØ§Ø±ÙŠØ® Ø¨Ù†Ø¬Ø§Ø­.")
else:
    st.warning("âš ï¸ Ù„Ù… ÙŠÙØ¹Ø«Ø± Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ 'Ø¢Ø®Ø± Ø§ØªØµØ§Ù„' ÙÙŠ Ø§Ù„Ù…Ù„Ù.")

# ============ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„ÙØ§Øª Ø§Ù„ÙØ­Øµ ÙˆØ§Ù„ØµÙŠØ§Ù†Ø© ============
def read_task_file(f, kind):
    if f is None:
        return pd.DataFrame()
    df = pd.read_excel(f)
    col_pre = pick_col(df, ["Premise", "Utility Site Id", "Ø±Ù‚Ù… Ø§Ù„Ù…ÙƒØ§Ù†"])
    col_reg = pick_col(df, ["Task Registration Date Time", "Request Registration Date Time", "ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ³Ø¬ÙŠÙ„"])
    col_close = pick_col(df, ["Task Closed Time", "Task Completed Time", "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù‚ÙØ§Ù„"])
    col_status = pick_col(df, ["Task Status", "Request Status", "Ø§Ù„Ø­Ø§Ù„Ø©"])
    col_result = pick_col(df, ["Technician's Result", "Final Result", "Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©"])
    df["_KEY_PREMISE"] = df[col_pre].astype(str).str.strip()
    for c in [col_reg, col_close]:
        if c in df.columns:
            df[c] = smart_parse_datetime(df[c])
    df["Ù†ÙˆØ¹ Ø§Ù„Ù…Ù‡Ù…Ø©"] = kind
    return df

insp_df = read_task_file(insp_file, "ÙØ­Øµ")
maint_df = read_task_file(maint_file, "ØµÙŠØ§Ù†Ø©")

# ============ Ø§Ù„Ø¯Ù…Ø¬ ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ ============
st.subheader("ğŸ”— ØªØ­Ù„ÙŠÙ„ ÙˆØ¯Ù…Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

summary = dis_df.copy()
summary = summary.rename(columns={col_last: "LastDaily"})
summary = summary[["_KEY_PREMISE", "LastDaily"] + [c for c in dis_df.columns if c not in ["_KEY_PREMISE", "LastDaily"]]]

def summarize_tasks(df, prefix):
    if df.empty:
        return pd.DataFrame(columns=["_KEY_PREMISE"])
    reg_col = pick_col(df, ["Task Registration Date Time", "Request Registration Date Time", "ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ³Ø¬ÙŠÙ„"])
    close_col = pick_col(df, ["Task Closed Time", "Task Completed Time", "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù‚ÙØ§Ù„"])
    status_col = pick_col(df, ["Task Status", "Request Status", "Ø§Ù„Ø­Ø§Ù„Ø©"])
    result_col = pick_col(df, ["Technician's Result", "Final Result", "Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©"])
    df["_open"] = df[close_col].isna() if close_col in df.columns else df[status_col].astype(str).str.lower().ne("closed")
    out = df.groupby("_KEY_PREMISE").agg(
        total_tasks=(status_col, "count"),
        open_tasks=("_open", "sum"),
        last_status=(status_col, "last"),
        last_result=(result_col, "last"),
        last_date=(close_col, "max")
    ).reset_index()
    out = out.add_prefix(prefix)
    out = out.rename(columns={f"{prefix}_KEY_PREMISE": "_KEY_PREMISE"})
    return out

insp_summary = summarize_tasks(insp_df, "insp")
maint_summary = summarize_tasks(maint_df, "maint")

summary = summary.merge(insp_summary, on="_KEY_PREMISE", how="left")
summary = summary.merge(maint_summary, on="_KEY_PREMISE", how="left")

# ============ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„ØªØ§Ù„ÙŠ ============
def next_action(row):
    if row.get("maintopen_tasks", 0) > 0:
        return "ØªØ³Ø±ÙŠØ¹ ØµÙŠØ§Ù†Ø© Ù…ÙØªÙˆØ­Ø©"
    elif row.get("inspopen_tasks", 0) > 0:
        return "Ù…ØªØ§Ø¨Ø¹Ø© ÙØ­Øµ Ù…ÙØªÙˆØ­"
    else:
        return "ÙŠÙØªØ­ ÙØ­Øµ Ø¬Ø¯ÙŠØ¯"

summary["Next Action"] = summary.apply(next_action, axis=1)

# ============ Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ============
st.subheader("ğŸ“ˆ Ù…Ø¤Ø´Ø±Ø§Øª Ø¹Ø§Ù…Ø©")
c1, c2, c3 = st.columns(3)
c1.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ø¯Ø§Ø¯Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ØªØµÙ„Ø©", f"{len(summary):,}")
c2.metric("Ù…Ù‡Ø§Ù… ÙØ­Øµ Ù…ÙØªÙˆØ­Ø©", int(summary["inspopen_tasks"].fillna(0).sum()))
c3.metric("Ù…Ù‡Ø§Ù… ØµÙŠØ§Ù†Ø© Ù…ÙØªÙˆØ­Ø©", int(summary["maintopen_tasks"].fillna(0).sum()))

st.subheader("ğŸ“‹ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…ÙˆØ­Ø¯")
st.dataframe(summary, use_container_width=True)

# ============ Ø§Ù„ØªÙ†Ø²ÙŠÙ„ ============
excel_data = to_excel_download(summary)
st.download_button(
    label="â¬‡ï¸ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨ØµÙŠØºØ© Excel",
    data=excel_data,
    file_name=f"premise_tracker_results_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
)
